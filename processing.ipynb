{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%store -r volume old"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\kmm171\\ImageAnalysis\\caImageAnalysis')\n",
    "from natsort import natsorted\n",
    "from scipy.stats import linregress\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "\n",
    "#local imports\n",
    "import main.main_eva as main_eva\n",
    "import main.main_improv2 as improv\n",
    "from utilities.pathutils import pathcrawler\n",
    "from utilities.create_ColorDict import hex_to_RGB as hex_to_RGB\n",
    "from utilities.arrutils import findmaxvalue\n",
    "from caImageAnalysis.constants import monocular_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "basefolder = r'C:\\Users\\kmm171\\Desktop\\Data\\improv\\training_data\\20240125_7dpf'\n",
    "fish1 = r'C:\\Users\\kmm171\\Desktop\\Data\\improv\\training_data\\20240125_7dpf\\139_eval3h2bgcamp6s_7dpf_fed_mono_R_20240125'\n",
    "fish2 = r'C:\\Users\\kmm171\\Desktop\\Data\\improv\\training_data\\20240125_7dpf\\140b_eval3h2bgcamp6s_7dpf_fed_mono_R_20240125'\n",
    "fish3 = r'C:\\Users\\kmm171\\Desktop\\Data\\improv\\training_data\\20240125_7dpf\\141_eval3h2bgcamp6s_7dpf_fed_mono_R_20240125'\n",
    "fish4 = r'C:\\Users\\kmm171\\Desktop\\Data\\improv\\training_data\\20240125_7dpf\\142_eval3h2bgcamp6s_7dpf_fed_mono_R_20240125'\n",
    "fish5 = r'C:\\Users\\kmm171\\Desktop\\Data\\improv\\training_data\\20240125_7dpf\\143_eval3h2bgcamp6s_7dpf_unfed_mono_R_20240125'\n",
    "fish6 = r'C:\\Users\\kmm171\\Desktop\\Data\\improv\\training_data\\20240125_7dpf\\144_eval3h2bgcamp6s_7dpf_unfed_mono_R_20240125'\n",
    "\n",
    "fishpaths = {\n",
    "\n",
    "    \"fish\" + \"139_a\" : pathcrawler(fish1, set(), [], \"img_stack_0\"),\n",
    "    \"fish\" + \"139_b\" : pathcrawler(fish1, set(), [], \"img_stack_1\"),\n",
    "    \"fish\" + \"140b_a\" : pathcrawler(fish2, set(), [], \"img_stack_0\"),\n",
    "    \"fish\" + \"140b_b\" : pathcrawler(fish2, set(), [], \"img_stack_1\"),\n",
    "    \"fish\" + \"141_a\" : pathcrawler(fish3, set(), [], \"img_stack_0\"),\n",
    "    \"fish\" + \"141_b\" : pathcrawler(fish3, set(), [], \"img_stack_1\"),\n",
    "    \"fish\" + \"142_a\" : pathcrawler(fish4, set(), [], \"img_stack_0\"),\n",
    "    \"fish\" + \"142_b\" : pathcrawler(fish4, set(), [], \"img_stack_1\"),\n",
    "    \"fish\" + \"143_a\" : pathcrawler(fish5, set(), [], \"img_stack_0\"),\n",
    "    \"fish\" + \"143_b\" : pathcrawler(fish5, set(), [], \"img_stack_1\"),\n",
    "    \"fish\" + \"144_a\" : pathcrawler(fish6, set(), [], \"img_stack_0\"),\n",
    "    \"fish\" + \"144_b\" : pathcrawler(fish6, set(), [], \"img_stack_1\"),\n",
    "\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "{'fish139_a': ['C:\\\\Users\\\\kmm171\\\\Desktop\\\\Data\\\\improv\\\\training_data\\\\20240125_7dpf\\\\139_eval3h2bgcamp6s_7dpf_fed_mono_R_20240125\\\\img_stack_0'],\n 'fish139_b': ['C:\\\\Users\\\\kmm171\\\\Desktop\\\\Data\\\\improv\\\\training_data\\\\20240125_7dpf\\\\139_eval3h2bgcamp6s_7dpf_fed_mono_R_20240125\\\\img_stack_1'],\n 'fish140b_a': ['C:\\\\Users\\\\kmm171\\\\Desktop\\\\Data\\\\improv\\\\training_data\\\\20240125_7dpf\\\\140b_eval3h2bgcamp6s_7dpf_fed_mono_R_20240125\\\\img_stack_0'],\n 'fish140b_b': ['C:\\\\Users\\\\kmm171\\\\Desktop\\\\Data\\\\improv\\\\training_data\\\\20240125_7dpf\\\\140b_eval3h2bgcamp6s_7dpf_fed_mono_R_20240125\\\\img_stack_1'],\n 'fish141_a': ['C:\\\\Users\\\\kmm171\\\\Desktop\\\\Data\\\\improv\\\\training_data\\\\20240125_7dpf\\\\141_eval3h2bgcamp6s_7dpf_fed_mono_R_20240125\\\\img_stack_0'],\n 'fish141_b': ['C:\\\\Users\\\\kmm171\\\\Desktop\\\\Data\\\\improv\\\\training_data\\\\20240125_7dpf\\\\141_eval3h2bgcamp6s_7dpf_fed_mono_R_20240125\\\\img_stack_1'],\n 'fish142_a': ['C:\\\\Users\\\\kmm171\\\\Desktop\\\\Data\\\\improv\\\\training_data\\\\20240125_7dpf\\\\142_eval3h2bgcamp6s_7dpf_fed_mono_R_20240125\\\\img_stack_0'],\n 'fish142_b': ['C:\\\\Users\\\\kmm171\\\\Desktop\\\\Data\\\\improv\\\\training_data\\\\20240125_7dpf\\\\142_eval3h2bgcamp6s_7dpf_fed_mono_R_20240125\\\\img_stack_1'],\n 'fish143_a': ['C:\\\\Users\\\\kmm171\\\\Desktop\\\\Data\\\\improv\\\\training_data\\\\20240125_7dpf\\\\143_eval3h2bgcamp6s_7dpf_unfed_mono_R_20240125\\\\img_stack_0'],\n 'fish143_b': ['C:\\\\Users\\\\kmm171\\\\Desktop\\\\Data\\\\improv\\\\training_data\\\\20240125_7dpf\\\\143_eval3h2bgcamp6s_7dpf_unfed_mono_R_20240125\\\\img_stack_1'],\n 'fish144_a': ['C:\\\\Users\\\\kmm171\\\\Desktop\\\\Data\\\\improv\\\\training_data\\\\20240125_7dpf\\\\144_eval3h2bgcamp6s_7dpf_unfed_mono_R_20240125\\\\img_stack_0'],\n 'fish144_b': ['C:\\\\Users\\\\kmm171\\\\Desktop\\\\Data\\\\improv\\\\training_data\\\\20240125_7dpf\\\\144_eval3h2bgcamp6s_7dpf_unfed_mono_R_20240125\\\\img_stack_1']}"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fishpaths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "fishSchool = {}\n",
    "\n",
    "for k, path in fishpaths.items():\n",
    "    if volume:\n",
    "        stackpaths = pathcrawler(f'{path[0]}', set(), [], \"img_stack\")\n",
    "        for i, p in enumerate(stackpaths):\n",
    "            f = improv.Fish(p, stimkey=\"output\", old_stims=old)\n",
    "            fishSchool[f'{k}_{i}'] = f\n",
    "    else:\n",
    "        for i, p in enumerate(fishpaths[k]):\n",
    "            f = improv.Fish(p, stimkey=\"output\", old_stims=old)\n",
    "            fishSchool[f'{k}'] = f\n",
    "\n",
    "#no frametimes? revise each txt file in img_stacks for empty spaces"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "{'fish163': <main.main_improv2.Fish at 0x26591b07070>,\n 'fish164': <main.main_improv2.Fish at 0x26591b07160>,\n 'fish165': <main.main_improv2.Fish at 0x26591b070d0>,\n 'fish166': <main.main_improv2.Fish at 0x26591b070a0>,\n 'fish167': <main.main_improv2.Fish at 0x26591b87c70>}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fishSchool"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "for key, stack in fishSchool.items():\n",
    "    stack.parsePaths()\n",
    "    basepath = stack.dataPaths['image'].parents[0].joinpath('suite2p')\n",
    "\n",
    "    stack.dataPaths[\"suite2p\"] = {\n",
    "        \"iscell\": basepath.joinpath(\n",
    "            \"plane0/iscell.npy\"\n",
    "        ),\n",
    "        \"stats\": basepath.joinpath(\n",
    "            \"plane0/stat.npy\"\n",
    "        ),\n",
    "        \"ops\": basepath.joinpath(\n",
    "            \"plane0/ops.npy\"\n",
    "        ),\n",
    "        \"f_cells\": basepath.joinpath(\n",
    "            \"plane0/F.npy\"\n",
    "        ),\n",
    "        \"f_neuropil\": basepath.joinpath(\n",
    "            \"plane0/Fneu.npy\"\n",
    "        ),\n",
    "        \"spikes\": basepath.joinpath(\n",
    "            \"plane0/spks.npy\"\n",
    "        ),\n",
    "        \"data\": basepath.joinpath(\n",
    "            \"plane0/data.bin\"\n",
    "        ),\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "offset = 10\n",
    "\n",
    "responses_fishSchool = {}\n",
    "errors_fishSchool = {}\n",
    "bool_df_fishSchool = {}\n",
    "responders_bool_fishSchool = {}\n",
    "\n",
    "ops_fishSchool = {}\n",
    "iscell_fishSchool = {}\n",
    "stats_fishSchool = {}\n",
    "f_cells_fishSchool = {}\n",
    "\n",
    "\n",
    "for key, stack in fishSchool.items():\n",
    "    ops, iscell, stats, f_cells = stack.load_suite2p(stack.dataPaths['suite2p'])\n",
    "    f_cells = stack.new_norm_fdff(f_cells)\n",
    "\n",
    "    neuron_responses = {}\n",
    "    neuron_stds = {}\n",
    "\n",
    "    for stimulus in stack.stimulus_df_condensed.stim_name.unique():\n",
    "        stimmy_df = stack.stimulus_df_condensed[\n",
    "            stack.stimulus_df_condensed.stim_name == stimulus\n",
    "            ]\n",
    "\n",
    "        starts = stimmy_df['motion_frame'].values\n",
    "\n",
    "        allArrs = []\n",
    "        for start_val in starts:\n",
    "            stimArr = f_cells[:, start_val + 2 : start_val + 2 + offset]\n",
    "            bgArr = f_cells[:, start_val - offset : start_val - 1]\n",
    "            diffArr = np.nanmean(stimArr, axis=1) - np.nanmean(bgArr, axis=1)\n",
    "            allArrs.append(diffArr)\n",
    "        meanVals = np.nanmean(allArrs, axis=0)\n",
    "        stdVals = np.nanstd(allArrs, axis=0)\n",
    "\n",
    "        neuron_responses[stimulus] = meanVals\n",
    "        neuron_stds[stimulus] = stdVals\n",
    "\n",
    "    responses = pd.DataFrame(neuron_responses)\n",
    "    errors = pd.DataFrame(neuron_stds)\n",
    "    bool_df = responses > errors #Change responses >= errors\n",
    "    responders = bool_df[bool_df.sum(axis=1) > 0]\n",
    "\n",
    "    f_cells = pd.DataFrame(f_cells)\n",
    "\n",
    "    ###\n",
    "    responses_fishSchool[key] = responses\n",
    "    errors_fishSchool[key] = errors\n",
    "    bool_df_fishSchool[key] = bool_df\n",
    "    responders_bool_fishSchool[key] = responders\n",
    "\n",
    "    ops_fishSchool[key] = ops\n",
    "    iscell_fishSchool[key] = iscell\n",
    "    stats_fishSchool[key] = stats\n",
    "    f_cells_fishSchool[key] = f_cells #these values are already normalized\n",
    "    ###\n",
    "\n",
    "#responders are already normalize. Each neuron has a max value, however, this max value might come from an outlier or from after the end of the trial or from the beginning of the recording. I would like to normalize each neuron response to highest response value across the entire experiment.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "responders_f_cells_fishSchool = {}\n",
    "#store in responders_fishSchool only those f_cells that are \"responders\"\n",
    "\n",
    "for key, stack in fishSchool.items():\n",
    "\n",
    "    responders_df = []\n",
    "    responders_idx = responders_bool_fishSchool[key].index.tolist()\n",
    "\n",
    "    for i, z in enumerate(responders_idx):\n",
    "        responsive_f_cells = f_cells_fishSchool[key].iloc[z].values\n",
    "        responders_df.append(responsive_f_cells)\n",
    "\n",
    "    responders_f_cells_fishSchool[key] = pd.DataFrame(responders_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "colors_fishSchool = {}\n",
    "\n",
    "for key, fish in fishSchool.items():\n",
    "\n",
    "    stimlist =  natsorted([e for e in fish.stimulus_df_condensed.stim_name.unique()])\n",
    "\n",
    "    colors = {}\n",
    "    color_dict = {}\n",
    "\n",
    "    for i, n in enumerate(stimlist): #range(1,max_stim_size+1):\n",
    "        color_dict[str(n)] = monocular_dict[i] #sns.color_palette(\"bright\", n_colors=len(stimlist))[i]\n",
    "    for k, v in color_dict.items():\n",
    "        old_colors = list(v)\n",
    "        fishSchool_alpha = [0.50]\n",
    "        colors[k] = old_colors + fishSchool_alpha\n",
    "\n",
    "    colors_fishSchool[key] = colors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "{'1.79': [1, 0.25, 0, 0.5],\n '3.58': [0, 0.25, 1, 0.5],\n '5.36': [0, 1, 0, 0.5],\n '7.13': [1, 0, 1, 0.5],\n '14.04': [0, 0.75, 1, 0.5],\n '20.56': [0.75, 1, 0, 0.5],\n '23.63': [0.25, 0, 1, 0.5],\n '26.57': [1, 0, 0.25, 0.5],\n '43.15': [0.25, 1, 0, 0.5],\n '48.37': [0, 0.75, 1, 0.5]}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors_fishSchool['fish163']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "cell_img_fishSchool = {}\n",
    "\n",
    "for key, stack in fishSchool.items():\n",
    "\n",
    "    cell_img = np.zeros((ops_fishSchool[key][\"Ly\"], ops_fishSchool[key][\"Lx\"], 4), 'float64') #start with a blank image\n",
    "\n",
    "    for row in range(len(responders_bool_fishSchool[key])):\n",
    "        cell = responders_bool_fishSchool[key].iloc[row]\n",
    "        nrn_color = [0,0,0,0]\n",
    "\n",
    "        for stim in colors_fishSchool[key].keys():\n",
    "            if cell.loc[float(stim)]:\n",
    "                nrn_color = [nrn_color[i] + colors_fishSchool[key][stim][i] for i in range(len(nrn_color))]\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        nrn_color = np.clip(nrn_color, a_min=0, a_max=1)\n",
    "        ypix = stats_fishSchool[key][cell.name]['ypix']\n",
    "        xpix = stats_fishSchool[key][cell.name]['xpix']\n",
    "\n",
    "        for n, c in enumerate(nrn_color):\n",
    "            cell_img[ypix, xpix, n] = c\n",
    "\n",
    "    cell_img_fishSchool[key] = cell_img"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "stacked_resp_fishSchool = {}\n",
    "\n",
    "offsetBaseline = 5\n",
    "afterstim_frames = offset + 10\n",
    "\n",
    "for key, fish in fishSchool.items():\n",
    "\n",
    "    warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "    mini_stim = pd.DataFrame()\n",
    "    mini_stim[['stim_name','motion']] = fish.stimulus_df_condensed[['stim_name','motion_frame']]\n",
    "\n",
    "    nrns_df = pd.DataFrame()\n",
    "    data = responders_f_cells_fishSchool[key]\n",
    "\n",
    "    for neuron in range(len(data)): #a single neuron #Change: only the first 30 responders to go further\n",
    "        all_resps_dict = {}\n",
    "        all_resps_list = []\n",
    "\n",
    "        for stim, group in mini_stim.groupby('stim_name'):\n",
    "\n",
    "            groupedbystim = []\n",
    "\n",
    "            for stimstart in group.motion:\n",
    "\n",
    "                chunksize = len(data.iloc[neuron, mini_stim['motion'][0]-offsetBaseline : mini_stim['motion'][0]+afterstim_frames]) # compares every response to the first response of the same neuron. check the length of the first response to guide the size of the other vectors\n",
    "\n",
    "                chunk = np.array(data.iloc[neuron, stimstart-offsetBaseline : stimstart+afterstim_frames])\n",
    "\n",
    "                if len(chunk) < chunksize:\n",
    "                    diff = chunksize - len(chunk)\n",
    "                    chunk_sm = np.array(data.iloc[neuron, stimstart-offsetBaseline : stimstart+afterstim_frames+diff])\n",
    "                    groupedbystim.append(chunk_sm)\n",
    "\n",
    "                elif len(chunk) > chunksize:\n",
    "                    diff =  len(chunk) - chunksize\n",
    "                    chunk_lg = np.array(data.iloc[neuron, stimstart-offsetBaseline : stimstart+afterstim_frames-diff])\n",
    "                    groupedbystim.append(chunk_lg)\n",
    "\n",
    "                else:\n",
    "                    chunk = np.array(data.iloc[neuron, stimstart-offsetBaseline : stimstart+afterstim_frames])\n",
    "                    groupedbystim.append(chunk)\n",
    "\n",
    "            all_resps_list.append(np.array(groupedbystim, dtype='object'))\n",
    "\n",
    "        all_resps_dict = dict(zip(mini_stim['stim_name'].unique().tolist(),all_resps_list))\n",
    "        singleneuron_df = pd.DataFrame({f'{neuron}' : all_resps_dict}).T #this is a big row = neuron with all trials\n",
    "        nrns_df = pd.concat([nrns_df, singleneuron_df])\n",
    "        nrns_df.columns = mini_stim['stim_name'].unique().tolist()\n",
    "\n",
    "    stacked_resp_fishSchool[key] = nrns_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "testdata = responders_f_cells_fishSchool['fish136b'].iloc[4]\n",
    "testdata = testdata[:].tolist()\n",
    "\n",
    "#specify path for export\n",
    "path = r'C:\\Users\\kmm171\\Desktop\\Data\\improv\\testdatafortuningcurve.txt'\n",
    "\n",
    "#export DataFrame to text file\n",
    "with open(path, 'w') as f:\n",
    "    for line in testdata:\n",
    "        f.write(\"%s\\n\" % line)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fish163 length: 72\n",
      "fish164 length: 28\n",
      "fish165 length: 43\n",
      "fish166 length: 24\n",
      "fish167 length: 34\n"
     ]
    }
   ],
   "source": [
    "responsive_neurons_fishSchool = {}\n",
    "responsive_bool_fishSchool = {}\n",
    "stacked_responsive_fishSchool = {}\n",
    "\n",
    "stimstart = offsetBaseline\n",
    "\n",
    "for key, fish in fishSchool.items():\n",
    "    stims = fish.stimulus_df_condensed['stim_name'].unique().tolist()\n",
    "    data = stacked_resp_fishSchool[key]\n",
    "\n",
    "    bool_df = pd.DataFrame()\n",
    "    neuronresp = pd.DataFrame()\n",
    "    responsive_neurons = pd.DataFrame()\n",
    "\n",
    "    for index, neuron in data.iterrows():\n",
    "\n",
    "        bool_resp = []\n",
    "        neuron_resp = []\n",
    "\n",
    "        for idx, chunk in neuron.items():\n",
    "            #Find whether the peak avg is significantly different from baseline\n",
    "            chunk = pd.DataFrame(chunk, dtype='float32') #this chunk has all the repetitions/trials\n",
    "            chunk_avg = chunk.mean(axis=0)\n",
    "            peak_index = chunk_avg.loc[stimstart:offset*2.5].idxmax()\n",
    "\n",
    "            initialresp = chunk_avg.loc[stimstart:peak_index+5]\n",
    "            peak = chunk_avg.loc[peak_index-8:peak_index+5]\n",
    "            peak_avg = peak.mean()\n",
    "            baseline_avg = chunk_avg.loc[:stimstart].mean()\n",
    "            baseline_std = chunk_avg.loc[:stimstart].std()\n",
    "\n",
    "            peakvalues = chunk[peak_index]\n",
    "            variance = peakvalues.var()\n",
    "            slope, intercept, r_value, p_value, std_err = linregress(x= range(len(initialresp)), y= initialresp)\n",
    "\n",
    "            if peak_avg > 1.4*baseline_std + baseline_avg: # and variance < 0.12:\n",
    "                if slope != 0:\n",
    "                    bool_resp.append(1)\n",
    "                    neuron_resp.append(peak_avg)\n",
    "                else:\n",
    "                    bool_resp.append(0)\n",
    "                    neuron_resp.append(0)\n",
    "            else:\n",
    "                bool_resp.append(0)\n",
    "                neuron_resp.append(0)\n",
    "\n",
    "        bool_DICT = dict(zip(stims,bool_resp))\n",
    "        singlebool_df = pd.DataFrame({f'{index}' : bool_DICT}).T\n",
    "        bool_df = pd.concat([bool_df, singlebool_df])\n",
    "        bool_df.columns = stims\n",
    "        bool_df = bool_df.loc[bool_df.sum(1) > 0]\n",
    "\n",
    "        resp_DICT = dict(zip(stims,neuron_resp))\n",
    "        resp_df = pd.DataFrame({f'{index}' : resp_DICT}).T\n",
    "        neuronresp = pd.concat([neuronresp, resp_df])\n",
    "        neuronresp.columns = stims\n",
    "        neuronresp = neuronresp.loc[neuronresp.sum(1) > 0]\n",
    "\n",
    "\n",
    "    responsive_bool_fishSchool[key] = bool_df\n",
    "    responsive_neurons_fishSchool[key] = neuronresp\n",
    "\n",
    "\n",
    "    print(f\"{key} length: {len(responsive_bool_fishSchool[key].index.tolist())}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "stacked_responsive_fishSchool = {}\n",
    "\n",
    "for key in fishSchool.keys():\n",
    "\n",
    "    df1 = responsive_bool_fishSchool[key]\n",
    "    df2 = stacked_resp_fishSchool[key]\n",
    "    df3 = df2[df2.index.isin(df1.index)]\n",
    "\n",
    "    stacked_responsive_fishSchool[key] = df3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "\n",
    "avgs_fishSchool = {}\n",
    "normsavgs_fishSchool = {}\n",
    "\n",
    "for key in fishSchool.keys():\n",
    "    data = stacked_resp_fishSchool[key]\n",
    "    fishavg = pd.DataFrame()\n",
    "\n",
    "    for idx in responsive_bool_fishSchool[key].index.tolist():\n",
    "        neuron = stacked_resp_fishSchool[key].loc[idx]\n",
    "\n",
    "        neuronavg = {}\n",
    "        for size, chunk in neuron.items():\n",
    "            chunkavg = np.mean(chunk,axis=0)\n",
    "            neuronavg[size] = chunkavg\n",
    "\n",
    "        neuronavg_df = pd.DataFrame({f'{idx}' : neuronavg}).T\n",
    "        fishavg = pd.concat([fishavg, neuronavg_df])\n",
    "\n",
    "    avgs_fishSchool[key] = fishavg\n",
    "\n",
    "\n",
    "\n",
    "    #normalize each neuron to its own peak value\n",
    "    fishnormavg = pd.DataFrame()\n",
    "\n",
    "    for idx, row in fishavg.iterrows():\n",
    "        maxvalue = row.explode().max()\n",
    "        minvalue = row.explode().min()\n",
    "\n",
    "        normneuron = {}\n",
    "        for size, chunk in row.items():\n",
    "            #normchunk = np.divide(chunk, maxvalue)\n",
    "            normchunk = (chunk - minvalue) / (maxvalue - minvalue)\n",
    "            normneuron[size] = normchunk\n",
    "\n",
    "        normneuron_df = pd.DataFrame({f'{idx}' : normneuron}).T\n",
    "        fishnormavg = pd.concat([fishnormavg, normneuron_df])\n",
    "\n",
    "    normsavgs_fishSchool[key] = fishnormavg\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "cell_img_fishSchool = {}\n",
    "for key, stack in fishSchool.items():\n",
    "    cell_img = np.zeros((ops_fishSchool[key][\"Ly\"], ops_fishSchool[key][\"Lx\"], 4), 'float64') #start with a blank image\n",
    "\n",
    "    for row in range(len(responders_bool_fishSchool[key])):\n",
    "        cell = responders_bool_fishSchool[key].iloc[row]\n",
    "\n",
    "        nrn_color = [0,0,0,0]\n",
    "\n",
    "        for stim in colors_fishSchool[key].keys():\n",
    "            if cell.loc[float(stim)]:\n",
    "                nrn_color = [nrn_color[i] + colors_fishSchool[key][stim][i] for i in range(len(nrn_color))]\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        nrn_color = np.clip(nrn_color, a_min=0, a_max=1)\n",
    "        ypix = stats_fishSchool[key][cell.name]['ypix']\n",
    "        xpix = stats_fishSchool[key][cell.name]['xpix']\n",
    "\n",
    "        for n, c in enumerate(nrn_color):\n",
    "            cell_img[ypix, xpix, n] = c\n",
    "\n",
    "    cell_img_fishSchool[key] = cell_img"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "responsive_cell_img_fishSchool = {}\n",
    "neurons_xypos= {}\n",
    "\n",
    "for key, stack in fishSchool.items():\n",
    "    cell_img = np.zeros((ops_fishSchool[key][\"Ly\"], ops_fishSchool[key][\"Lx\"], 4), 'float64') #start with a blank image\n",
    "\n",
    "    xpos_coordinates = []\n",
    "    ypos_coordinates = []\n",
    "    cells_id = []\n",
    "    cells_color = []\n",
    "\n",
    "    for row in range(len(responsive_bool_fishSchool[key])):\n",
    "        cell = responsive_bool_fishSchool[key].iloc[row]\n",
    "\n",
    "        nrn_color = [0,0,0,0]\n",
    "\n",
    "        for stim in colors_fishSchool[key].keys():\n",
    "            if cell.loc[float(stim)]:\n",
    "                nrn_color = [nrn_color[i] + colors_fishSchool[key][stim][i] for i in range(len(nrn_color))]\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        nrn_color = np.clip(nrn_color, a_min=0, a_max=1)\n",
    "        ypix = stats_fishSchool[key][int(cell.name)]['ypix']\n",
    "        xpix = stats_fishSchool[key][int(cell.name)]['xpix']\n",
    "\n",
    "        for n, c in enumerate(nrn_color):\n",
    "            cell_img[ypix, xpix, n] = c\n",
    "\n",
    "        cell_coordinates = stats_fishSchool[key][int(cell.name)]['med']\n",
    "\n",
    "        xpos_coordinates.append(cell_coordinates[1])\n",
    "        ypos_coordinates.append(cell_coordinates[0])\n",
    "        cells_id.append(int(cell.name))\n",
    "        cells_color.append(nrn_color)\n",
    "\n",
    "    xypos_dict = {}\n",
    "    xypos_dict['cell_id'] = cells_id\n",
    "    xypos_dict['color'] = cells_color\n",
    "    xypos_dict['xpos'] = xpos_coordinates\n",
    "    xypos_dict['ypos'] = ypos_coordinates\n",
    "\n",
    "    neurons_xypos[key] = xypos_dict\n",
    "    responsive_cell_img_fishSchool[key] = cell_img"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'fishpaths' (dict)\n",
      "Stored 'fishSchool' (dict)\n",
      "Stored 'responses_fishSchool' (dict)\n",
      "Stored 'errors_fishSchool' (dict)\n",
      "Stored 'bool_df_fishSchool' (dict)\n",
      "Stored 'responders_bool_fishSchool' (dict)\n",
      "Stored 'responders_f_cells_fishSchool' (dict)\n",
      "Stored 'ops_fishSchool' (dict)\n",
      "Stored 'iscell_fishSchool' (dict)\n",
      "Stored 'stats_fishSchool' (dict)\n",
      "Stored 'f_cells_fishSchool' (dict)\n",
      "Stored 'offset' (int)\n",
      "Stored 'stacked_resp_fishSchool' (dict)\n",
      "Stored 'offsetBaseline' (int)\n",
      "Stored 'afterstim_frames' (int)\n",
      "Stored 'colors_fishSchool' (dict)\n",
      "Stored 'cell_img_fishSchool' (dict)\n",
      "Stored 'responsive_neurons_fishSchool' (dict)\n",
      "Stored 'responsive_bool_fishSchool' (dict)\n",
      "Stored 'responsive_cell_img_fishSchool' (dict)\n",
      "Stored 'neurons_xypos' (dict)\n",
      "Stored 'stacked_resp_fishSchool' (dict)\n",
      "Stored 'normsavgs_fishSchool' (dict)\n",
      "Stored 'avgs_fishSchool' (dict)\n",
      "Stored 'stacked_responsive_fishSchool' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store fishpaths fishSchool responses_fishSchool errors_fishSchool bool_df_fishSchool responders_bool_fishSchool responders_f_cells_fishSchool ops_fishSchool iscell_fishSchool stats_fishSchool f_cells_fishSchool offset stacked_resp_fishSchool offsetBaseline afterstim_frames colors_fishSchool cell_img_fishSchool responsive_neurons_fishSchool responsive_bool_fishSchool responsive_cell_img_fishSchool neurons_xypos stacked_resp_fishSchool normsavgs_fishSchool avgs_fishSchool stacked_responsive_fishSchool"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
